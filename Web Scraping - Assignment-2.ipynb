{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80f701c7",
   "metadata": {},
   "source": [
    "# Assigment - 2 - Web Scrapping\n",
    "By Mónica Atiaga\n",
    "\n",
    "Batch - DSNB1222\n",
    "\n",
    "1. All the questions must be done in a single Jupyternotebook.\n",
    "2. There should be proper comments in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7f4fd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8767ee51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting webdriver-manager\n",
      "  Downloading webdriver_manager-3.8.6-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\monica\\anaconda3\\lib\\site-packages (from webdriver-manager) (21.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\monica\\anaconda3\\lib\\site-packages (from webdriver-manager) (4.64.1)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\monica\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.28.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\monica\\anaconda3\\lib\\site-packages (from packaging->webdriver-manager) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\monica\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\monica\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\monica\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\monica\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\monica\\anaconda3\\lib\\site-packages (from tqdm->webdriver-manager) (0.4.5)\n",
      "Installing collected packages: python-dotenv, webdriver-manager\n",
      "Successfully installed python-dotenv-1.0.0 webdriver-manager-3.8.6\n"
     ]
    }
   ],
   "source": [
    "#!pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d96967",
   "metadata": {},
   "source": [
    "**Q1:** Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You \n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 \n",
    "jobs data.\n",
    "This task will be done in following steps:\n",
    "\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the \n",
    "location” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then scrape the data for the first 10 jobs results youget.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "**Note: All of the above steps have to be done in code. No step is to be done manuall**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d77835e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"http://www.naukri.com/\")\n",
    "\n",
    "designation = driver.find_element(By.CLASS_NAME, \"suggestor-input\")\n",
    "designation.send_keys('Data Analyst')\n",
    "\n",
    "location = driver.find_element(By.XPATH, \"/html/body/div/div[7]/div/div/div[5]/div/div/div/div[1]/div/input\")\n",
    "location.send_keys('Bangalore')\n",
    "\n",
    "search = driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07176c27",
   "metadata": {},
   "source": [
    "**Q2:** Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You \n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then scrape the data for the first 10 jobs results youget.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "**Note: All of the above steps have to be done in code. No step is to be done manually**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94f0990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6252e029",
   "metadata": {},
   "source": [
    "**Q3:** In this question you have to scrape data using the filters available on the webpage as shown below\n",
    "\n",
    "You have to use the location and salary filter.\n",
    "\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "\n",
    "You have to scrape the job-title, job-location, company name, experience required. \n",
    "\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "\n",
    "The task will be done as shown in the below steps:\n",
    "\n",
    "1. first get thewebpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then apply the location filter and salary filter by checking the respectiveboxes\n",
    "5. Then scrape the data for the first 10 jobs results youget.\n",
    "6. Finally create a dataframe of the scrapeddata.\n",
    "**Note: All of the above steps have to be done in code. No step is to be done manually.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4563c154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c30e4ad8",
   "metadata": {},
   "source": [
    "**Q4:** Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "\n",
    "The attributes which you have to scrape is ticked marked in the below image\n",
    "\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url :https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the required data as usual.\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom other page , then click on it.\n",
    "5. Now scrap data from this page as usual\n",
    "6. Repeat this until you get data for 100 sunglasses.\n",
    "**Note: That all of the above steps have to be done by coding only and not manually.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "615f69d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "import regex as re\n",
    "import math\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "24fca365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_products_by_page(driver, n=None):\n",
    "    ''' Load the products with brand, description and price on the page.\n",
    "        n: number of products required\n",
    "        Return: a DataFrame with the info of the products\n",
    "    '''\n",
    "    # scraping Brands using list comprehension\n",
    "    brand_tags = driver.find_elements(By.XPATH, '//div[@class=\"_2WkVRV\"]')\n",
    "    brand = [ tag.text for tag in brand_tags]\n",
    "    print(\"Brands retrived:\", len(brand))\n",
    "    \n",
    "    # scraping Product Descriptions: some products  class=\"IRpwTa\" and other class=\"IRpwTa _2-ICcC\"\n",
    "    prod_tags = driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\" or @class=\"IRpwTa _2-ICcC\"]') \n",
    "    product_desc = [ tag.text for tag in prod_tags]\n",
    "    print(\"Desc. retrived:\", len(product_desc))\n",
    "\n",
    "    \n",
    "    # scraping Price\n",
    "    price_tags = driver.find_elements(By.XPATH, '//div[@class=\"_30jeq3\"]')\n",
    "    price = [tag.text for tag in price_tags]\n",
    "    print(\"Prices retrived:\", len(price))\n",
    "    \n",
    "    # % off \n",
    "    poff_tags = driver.find_elements(By.XPATH, '//div[@class=\"_3Ay6Sb\"]')\n",
    "    p_off = [tag.text for tag in poff_tags]\n",
    "    print(\"% off retived:\", len(p_off))\n",
    "    \n",
    "     \n",
    "    if(len(brand) == len(product_desc) and len(brand) == len(price) and len(brand)==len(p_off)):\n",
    "        # n=None or the required records are equal or more than the retrived records\n",
    "        if (not(n) or len(brand)<=n):\n",
    "            return pd.DataFrame({'Brand': brand,\n",
    "                              'Product description': product_desc,\n",
    "                              'Price': price,\n",
    "                              '% off': p_off})\n",
    "        elif(len(brand)> n):\n",
    "            return pd.DataFrame({'Brand': brand[:n],\n",
    "                              'Product description': product_desc[:n],\n",
    "                              'Price': price[:n],\n",
    "                              '% off': p_off[:n]})\n",
    "    \n",
    "    return pd.DataFrame()\n",
    "\n",
    "def go_next_page(driver, i):\n",
    "    ''' Go to the next page of products'''\n",
    "    next_btn = driver.find_elements(By.XPATH, '//a[@class=\"ge-49M\"]')\n",
    "    \n",
    "    # scroll until button be visible\n",
    "    actions = ActionChains(driver)\n",
    "    actions.move_to_element(next_btn[i]).perform()\n",
    "\n",
    "    # Wait until the button be visible (loading compleated)\n",
    "    wait = WebDriverWait(driver, 30)\n",
    "    wait.until(EC.element_to_be_clickable((By.XPATH, '//a[@class=\"ge-49M\"]')))\n",
    "\n",
    "    # Click the button once it is clickable\n",
    "    next_btn[i].click()\n",
    "    \n",
    "\n",
    "def wait_random(driver):\n",
    "    '''Simulate random number of timeouts'''\n",
    "    time_to_wait = random.choice([60, 15, 30, 45])\n",
    "    print(f\"Waiting..{time_to_wait} seconds.\")\n",
    "    WebDriverWait(driver, time_to_wait)   # Esperar hasta n segundos\n",
    "    \n",
    "def retrive_product_per_page(driver):\n",
    "    # Retrive the total number of products from the search and \n",
    "    # the number of products on the retrived page\n",
    "    reg = driver.find_element(By.XPATH, '//span[@class=\"_10Ermr\"]')\n",
    "\n",
    "    pattern = r'\\b\\d{1,3}(?:,\\d{3})*\\b|\\b\\d+\\b'\n",
    "    matches = re.findall(pattern, reg.text)\n",
    "    numbers_without_commas = [match.replace(',', '') for match in matches]\n",
    "    reg_1st, reg_2d, tot_reg = [*map(int, numbers_without_commas)]\n",
    "    \n",
    "    return [reg_1st, \n",
    "            reg_2d, \n",
    "            tot_reg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6f4d86b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_products(df):\n",
    "    # Cleaning the data\n",
    "    pattern = r'(\\d+%)'\n",
    "    df['% off'] = df['% off'].str.extract(pattern)\n",
    "\n",
    "    # Reseting index\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return (df)\n",
    "    \n",
    "def remove_popup():\n",
    "    # Check if an element on the new page is present\n",
    "    try:\n",
    "        close_button  = driver.find_element(By.XPATH, '//button[@class=\"_2KpZ6l _2doB4z\"]')\n",
    "        close_button.click() \n",
    "        print(\"Pop-up removed\")\n",
    "    except NoSuchElementException:\n",
    "        print(\"No pop-up windows was found\")\n",
    "\n",
    "\n",
    "def retrieve_products(n):\n",
    "    ''' Retrieve the products advancing page by page until completing all \"n\" products.\n",
    "        Return: a dataframe with the products'''\n",
    "    # Checking the found records\n",
    "    first, second, total = retrive_product_per_page(driver)\n",
    "    total_records_to_retrive = n\n",
    "\n",
    "    if(total < total_records_to_retrive):\n",
    "        total_records_to_retrive = total\n",
    "\n",
    "    df_products = pd.DataFrame()\n",
    "    i = 0 \n",
    "\n",
    "    while( total_records_to_retrive > 0 ):\n",
    "\n",
    "        print('*'*40, 'i=' ,i)\n",
    "\n",
    "        wait_time = 10\n",
    "        time.sleep(wait_time)\n",
    "\n",
    "        df = load_products_by_page(driver, total_records_to_retrive) \n",
    "        df_products = pd.concat([df_products,df])\n",
    "\n",
    "        total_records_to_retrive -= len(df)\n",
    "\n",
    "        print(\"total_records_to_retrive left\", total_records_to_retrive)\n",
    "        print(\"retrived records:\", len(df_products))\n",
    "\n",
    "        if (total_records_to_retrive > 0):\n",
    "            wait_random(driver)\n",
    "            go_next_page(driver, i)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    print( f'Products retrived successfully: {len(df_products)}' )\n",
    "    return (df_products)\n",
    "        \n",
    "        \n",
    "def search_product(product):\n",
    "    try:\n",
    "        input = driver.find_element(By.XPATH, '//input[@class=\"Pke_EE\" or @class=\"_3704LK\"]') \n",
    "        input.send_keys(product)\n",
    "        print(f\"Search for {product}\")\n",
    "\n",
    "        WebDriverWait(driver, 10)\n",
    "\n",
    "        btn = driver.find_element(By.XPATH, '//button[@class=\"_2iLD__\" or @class=\"L0Z3Pu\"]') \n",
    "        btn.click()\n",
    "        print(\"Click successful\")\n",
    "\n",
    "    except NoSuchElementException:\n",
    "        print(\"An element wasn't found.\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f1609c7",
   "metadata": {},
   "source": [
    "Web scraping - Begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "416bf06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7d1785bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pop-up removed\n"
     ]
    }
   ],
   "source": [
    "driver.get(\"https://www.flipkart.com/\")\n",
    "\n",
    "# Closing pop-up window\n",
    "wait = WebDriverWait(driver, 30)\n",
    "\n",
    "remove_popup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "46dd3bb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search for sunglasses\n",
      "Click successful\n"
     ]
    }
   ],
   "source": [
    "product = 'sunglasses'\n",
    "search_product(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0afa90e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************** i= 0\n",
      "Brands retrived: 40\n",
      "Desc. retrived: 40\n",
      "Prices retrived: 40\n",
      "% off retived: 40\n",
      "total_records_to_retrive left 60\n",
      "retrived records: 40\n",
      "Waiting..30 seconds.\n",
      "**************************************** i= 1\n",
      "Brands retrived: 40\n",
      "Desc. retrived: 40\n",
      "Prices retrived: 40\n",
      "% off retived: 39\n",
      "total_records_to_retrive left 60\n",
      "retrived records: 40\n",
      "Waiting..45 seconds.\n",
      "**************************************** i= 2\n",
      "Brands retrived: 40\n",
      "Desc. retrived: 40\n",
      "Prices retrived: 40\n",
      "% off retived: 40\n",
      "total_records_to_retrive left 20\n",
      "retrived records: 80\n",
      "Waiting..15 seconds.\n",
      "**************************************** i= 3\n",
      "Brands retrived: 40\n",
      "Desc. retrived: 40\n",
      "Prices retrived: 40\n",
      "% off retived: 40\n",
      "total_records_to_retrive left 0\n",
      "retrived records: 100\n",
      "Products retrived successfully: 100\n"
     ]
    }
   ],
   "source": [
    "df_products = retrieve_products(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3c7ead00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cecking the size of dataframe\n",
    "df_products.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d15d2889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product description</th>\n",
       "      <th>Price</th>\n",
       "      <th>% off</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Rich Club</td>\n",
       "      <td>Polarized Round Sunglasses (48)</td>\n",
       "      <td>₹193</td>\n",
       "      <td>61%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>CHORIOTIS</td>\n",
       "      <td>UV Protection, Riding Glasses, Mirrored Round ...</td>\n",
       "      <td>₹1,999</td>\n",
       "      <td>25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>IDEE</td>\n",
       "      <td>Gradient Butterfly Sunglasses (64)</td>\n",
       "      <td>₹2,275</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SUNBEE</td>\n",
       "      <td>UV Protection Cat-eye Sunglasses (Free Size)</td>\n",
       "      <td>₹199</td>\n",
       "      <td>66%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (32)</td>\n",
       "      <td>₹259</td>\n",
       "      <td>83%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand                                Product description   Price % off\n",
       "95  Rich Club                    Polarized Round Sunglasses (48)    ₹193   61%\n",
       "96  CHORIOTIS  UV Protection, Riding Glasses, Mirrored Round ...  ₹1,999   25%\n",
       "97       IDEE                 Gradient Butterfly Sunglasses (64)  ₹2,275   30%\n",
       "98     SUNBEE       UV Protection Cat-eye Sunglasses (Free Size)    ₹199   66%\n",
       "99     PIRASO             UV Protection Wayfarer Sunglasses (32)    ₹259   83%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_products = cleaning_products(df_products)    \n",
    "display(df_products.tail())\n",
    "\n",
    "# Saving the result dataset\n",
    "df_products.to_csv('webScraping2_datasets/q4_products.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "92b8da9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f12003",
   "metadata": {},
   "source": [
    "**Q5:** Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: \n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART\n",
    "\n",
    "As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100reviews.\n",
    "**Note: All the steps required during scraping should be done through code only and not manually.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2477ab86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "525b4258",
   "metadata": {},
   "source": [
    "**Q6:** Scrape data forfirst 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the \n",
    "search field.\n",
    "\n",
    "You have to scrape 3 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. ProductDescription\n",
    "3. Price\n",
    "\n",
    "As shown in the below image, you have to scrape the above attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b7b9084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6cafb53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pop-up removed\n"
     ]
    }
   ],
   "source": [
    "driver.get(\"https://www.flipkart.com/\")\n",
    "\n",
    "# Closing pop-up window\n",
    "wait = WebDriverWait(driver, 30)\n",
    "\n",
    "remove_popup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5d16bd24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search for sneakers\n",
      "Click successful\n"
     ]
    }
   ],
   "source": [
    "product = 'sneakers'\n",
    "search_product(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e465d832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************** i= 0\n",
      "Brands retrived: 40\n",
      "Desc. retrived: 40\n",
      "Prices retrived: 40\n",
      "% off retived: 40\n",
      "total_records_to_retrive left 60\n",
      "retrived records: 40\n",
      "Waiting..60 seconds.\n",
      "**************************************** i= 1\n"
     ]
    }
   ],
   "source": [
    "df_products = retrieve_products(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5ef8f9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product description</th>\n",
       "      <th>Price</th>\n",
       "      <th>% off</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Airson</td>\n",
       "      <td>Junior Zero1 Sports shoes for Men | Gym Traini...</td>\n",
       "      <td>₹989</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sparx</td>\n",
       "      <td>Stylish and Comfirtable Shoes For Mens Sneaker...</td>\n",
       "      <td>₹749</td>\n",
       "      <td>16% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Synthetic Leather |Lightweight|Comfort|Summer|...</td>\n",
       "      <td>₹399</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nobelite</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹289</td>\n",
       "      <td>71% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹299</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>asian</td>\n",
       "      <td>SM-162 Black Walking ,Training,Sneakers,Loafer...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>28% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹559</td>\n",
       "      <td>44% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Abros</td>\n",
       "      <td>Flex Sneakers For Men</td>\n",
       "      <td>₹1,521</td>\n",
       "      <td>30% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Hustle V2 Sneakers For Men</td>\n",
       "      <td>₹1,599</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Kraasa</td>\n",
       "      <td>Sneakers For Women</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Brand                                Product description   Price  \\\n",
       "0     Airson  Junior Zero1 Sports shoes for Men | Gym Traini...    ₹989   \n",
       "1      Sparx  Stylish and Comfirtable Shoes For Mens Sneaker...    ₹749   \n",
       "2       aadi  Synthetic Leather |Lightweight|Comfort|Summer|...    ₹399   \n",
       "3   Nobelite                                   Sneakers For Men    ₹289   \n",
       "4       aadi                                   Sneakers For Men    ₹299   \n",
       "..       ...                                                ...     ...   \n",
       "15     asian  SM-162 Black Walking ,Training,Sneakers,Loafer...    ₹499   \n",
       "16  RapidBox                                   Sneakers For Men    ₹559   \n",
       "17     Abros                              Flex Sneakers For Men  ₹1,521   \n",
       "18      PUMA                         Hustle V2 Sneakers For Men  ₹1,599   \n",
       "19    Kraasa                                 Sneakers For Women    ₹399   \n",
       "\n",
       "      % off  \n",
       "0   55% off  \n",
       "1   16% off  \n",
       "2   80% off  \n",
       "3   71% off  \n",
       "4   85% off  \n",
       "..      ...  \n",
       "15  28% off  \n",
       "16  44% off  \n",
       "17  30% off  \n",
       "18  60% off  \n",
       "19  60% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_products.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "091ed623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product description</th>\n",
       "      <th>Price</th>\n",
       "      <th>% off</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>asian</td>\n",
       "      <td>SM-162 Black Walking ,Training,Sneakers,Loafer...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>28%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹559</td>\n",
       "      <td>44%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Abros</td>\n",
       "      <td>Flex Sneakers For Men</td>\n",
       "      <td>₹1,521</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Hustle V2 Sneakers For Men</td>\n",
       "      <td>₹1,599</td>\n",
       "      <td>60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Kraasa</td>\n",
       "      <td>Sneakers For Women</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Brand                                Product description   Price % off\n",
       "95     asian  SM-162 Black Walking ,Training,Sneakers,Loafer...    ₹499   28%\n",
       "96  RapidBox                                   Sneakers For Men    ₹559   44%\n",
       "97     Abros                              Flex Sneakers For Men  ₹1,521   30%\n",
       "98      PUMA                         Hustle V2 Sneakers For Men  ₹1,599   60%\n",
       "99    Kraasa                                 Sneakers For Women    ₹399   60%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cleaning the products and set index\n",
    "cleaning_products(df_products)    \n",
    "display(df_products.tail())\n",
    "\n",
    "# Saving the result dataset\n",
    "df_products.to_csv('webScraping2_datasets/q6_sneakers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7fd97663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5dc7ed",
   "metadata": {},
   "source": [
    "**Q7:** Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then \n",
    "set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cc8b9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dabdd2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.amazon.in/\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fe193a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting..140 seconds.\n"
     ]
    }
   ],
   "source": [
    "product = 'Laptop'\n",
    "\n",
    "input = driver.find_element(By.XPATH, '//input[@id=\"twotabsearchtextbox\"]') \n",
    "input.send_keys(product)\n",
    "\n",
    "wait_random(driver)\n",
    "\n",
    "btn = driver.find_element(By.XPATH, '//input[@id=\"nav-search-submit-button\"]') \n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d3bf66",
   "metadata": {},
   "source": [
    "**Q8:** Write a python program to scrape data for Top 1000 Quotes of All Time.\n",
    "The above task will be done in following steps:\n",
    "1. First get the webpage https://www.azquotes.com/\n",
    "2. Click on TopQuotes\n",
    "3. Than scrap a) Quote b) Author c) Type Of Quotes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c54625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93860add",
   "metadata": {},
   "source": [
    "**Q9:** Write a python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead, \n",
    "Term of office, Remarks) from https://www.jagranjosh.com/.\n",
    "\n",
    "This task will be done in following steps:\n",
    "1. First get the webpagehttps://www.jagranjosh.com/\n",
    "2. Then You have to click on the GK option\n",
    "3. Then click on the List of all Prime Ministers of India\n",
    "4. Then scrap the mentioned data and make theDataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2b2844",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7770946d",
   "metadata": {},
   "source": [
    "**Q10:** Write a python program to display list of 50 Most expensive cars in the world (i.e. \n",
    "Car name and Price) from https://www.motor1.com/\n",
    "\n",
    "This task will be done in following steps:\n",
    "1. First get the webpagehttps://www.motor1.com/\n",
    "2. Then You have to type in the search bar ’50 most expensive cars’\n",
    "3. Then click on 50 most expensive carsin the world..\n",
    "4. Then scrap the mentioned data and make the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c347ffef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
