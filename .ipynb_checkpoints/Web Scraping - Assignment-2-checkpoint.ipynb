{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80f701c7",
   "metadata": {},
   "source": [
    "# Assigment - 2 - Web Scrapping\n",
    "By Mónica Atiaga\n",
    "\n",
    "Batch - DSNB1222\n",
    "\n",
    "1. All the questions must be done in a single Jupyternotebook.\n",
    "2. There should be proper comments in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7f4fd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8767ee51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting webdriver-manager\n",
      "  Downloading webdriver_manager-3.8.6-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\monica\\anaconda3\\lib\\site-packages (from webdriver-manager) (21.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\monica\\anaconda3\\lib\\site-packages (from webdriver-manager) (4.64.1)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\monica\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.28.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\monica\\anaconda3\\lib\\site-packages (from packaging->webdriver-manager) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\monica\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\monica\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\monica\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\monica\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\monica\\anaconda3\\lib\\site-packages (from tqdm->webdriver-manager) (0.4.5)\n",
      "Installing collected packages: python-dotenv, webdriver-manager\n",
      "Successfully installed python-dotenv-1.0.0 webdriver-manager-3.8.6\n"
     ]
    }
   ],
   "source": [
    "#!pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d96967",
   "metadata": {},
   "source": [
    "**Q1:** Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You \n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 \n",
    "jobs data.\n",
    "This task will be done in following steps:\n",
    "\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the \n",
    "location” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then scrape the data for the first 10 jobs results youget.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "**Note: All of the above steps have to be done in code. No step is to be done manuall**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d77835e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"http://www.naukri.com/\")\n",
    "\n",
    "designation = driver.find_element(By.CLASS_NAME, \"suggestor-input\")\n",
    "designation.send_keys('Data Analyst')\n",
    "\n",
    "location = driver.find_element(By.XPATH, \"/html/body/div/div[7]/div/div/div[5]/div/div/div/div[1]/div/input\")\n",
    "location.send_keys('Bangalore')\n",
    "\n",
    "search = driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07176c27",
   "metadata": {},
   "source": [
    "**Q2:** Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You \n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then scrape the data for the first 10 jobs results youget.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "**Note: All of the above steps have to be done in code. No step is to be done manually**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94f0990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6252e029",
   "metadata": {},
   "source": [
    "**Q3:** In this question you have to scrape data using the filters available on the webpage as shown below\n",
    "\n",
    "You have to use the location and salary filter.\n",
    "\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "\n",
    "You have to scrape the job-title, job-location, company name, experience required. \n",
    "\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "\n",
    "The task will be done as shown in the below steps:\n",
    "\n",
    "1. first get thewebpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then apply the location filter and salary filter by checking the respectiveboxes\n",
    "5. Then scrape the data for the first 10 jobs results youget.\n",
    "6. Finally create a dataframe of the scrapeddata.\n",
    "**Note: All of the above steps have to be done in code. No step is to be done manually.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4563c154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c30e4ad8",
   "metadata": {},
   "source": [
    "**Q4:** Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "\n",
    "The attributes which you have to scrape is ticked marked in the below image\n",
    "\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url :https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the required data as usual.\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom other page , then click on it.\n",
    "5. Now scrap data from this page as usual\n",
    "6. Repeat this until you get data for 100 sunglasses.\n",
    "**Note: That all of the above steps have to be done by coding only and not manually.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "615f69d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "import regex as re\n",
    "import math\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "24fca365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_products_by_page(driver, n=None):\n",
    "    ''' Load the products with brand, description and price on the page.\n",
    "        n: number of products required\n",
    "        Return: a DataFrame with the info of the products\n",
    "    '''\n",
    "    # scraping Brands using list comprehension\n",
    "    brand_tags = driver.find_elements(By.XPATH, '//div[@class=\"_2WkVRV\"]')\n",
    "    brand = [ tag.text for tag in brand_tags]\n",
    "    print(\"Brands retrived:\", len(brand))\n",
    "    \n",
    "    # scraping Product Descriptions: some products  class=\"IRpwTa\" and other class=\"IRpwTa _2-ICcC\"\n",
    "    prod_tags = driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\" or @class=\"IRpwTa _2-ICcC\"]') \n",
    "    product_desc = [ tag.text for tag in prod_tags]\n",
    "    print(\"Desc. retrived:\", len(product_desc))\n",
    "\n",
    "    \n",
    "    # scraping Price\n",
    "    price_tags = driver.find_elements(By.XPATH, '//div[@class=\"_30jeq3\"]')\n",
    "    price = [tag.text for tag in price_tags]\n",
    "    print(\"Prices retrived:\", len(price))\n",
    "    \n",
    "    # % off \n",
    "    poff_tags = driver.find_elements(By.XPATH, '//div[@class=\"_3Ay6Sb\"]')\n",
    "    p_off = [tag.text for tag in poff_tags]\n",
    "    print(\"% off retived:\", len(p_off))\n",
    "    \n",
    "     \n",
    "    if(len(brand) == len(product_desc) and len(brand) == len(price) and len(brand)==len(p_off)):\n",
    "        # n=None or the required records are equal or more than the retrived records\n",
    "        if (not(n) or len(brand)<=n):\n",
    "            return pd.DataFrame({'Brand': brand,\n",
    "                              'Product description': product_desc,\n",
    "                              'Price': price,\n",
    "                              '% off': p_off})\n",
    "        elif(len(brand)> n):\n",
    "            return pd.DataFrame({'Brand': brand[:n],\n",
    "                              'Product description': product_desc[:n],\n",
    "                              'Price': price[:n],\n",
    "                              '% off': p_off[:n]})\n",
    "    \n",
    "    return pd.DataFrame()\n",
    "\n",
    "def go_next_page2(driver, i):\n",
    "    ''' Go to the next page of products'''\n",
    "    if (i == 0):\n",
    "        next_pos = 11\n",
    "    else:\n",
    "        next_pos = 12\n",
    "        \n",
    "    next_btn = driver.find_element(By.XPATH, f'//nav[@class=\"yFHi8N\"]/a[{next_pos}]')\n",
    "    print(next_pos,  next_btn.text)\n",
    "    # scroll until button be visible\n",
    "    actions = ActionChains(driver)\n",
    "    actions.move_to_element(next_btn).perform()\n",
    "\n",
    "    # Wait until the button be visible (loading compleated)\n",
    "    wait = WebDriverWait(driver, 30)\n",
    "    wait.until(EC.element_to_be_clickable((By.XPATH, f'//nav[@class=\"yFHi8N\"]/a[{next_pos}]')))\n",
    "\n",
    "    # Click the button once it is clickable\n",
    "    next_btn.click()\n",
    "\n",
    "def wait_random(driver):\n",
    "    '''Simulate random number of timeouts'''\n",
    "    time_to_wait = random.choice([60, 15, 30, 45])\n",
    "    print(f\"Waiting..{time_to_wait} seconds.\")\n",
    "    WebDriverWait(driver, time_to_wait)   # Esperar hasta n segundos\n",
    "    \n",
    "def retrive_product_per_page(driver, xpath):\n",
    "    # Retrive the total number of products from the search and \n",
    "    # the number of products on the retrived page\n",
    "    reg = driver.find_element(By.XPATH, xpath)\n",
    "\n",
    "    pattern = r'\\b\\d{1,3}(?:,\\d{3})*\\b|\\b\\d+\\b'\n",
    "    matches = re.findall(pattern, reg.text)\n",
    "    numbers_without_commas = [match.replace(',', '') for match in matches]\n",
    "    nreg = [*map(int, numbers_without_commas)]\n",
    "    \n",
    "    return nreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "7b482590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_products(df):\n",
    "    # Cleaning the data\n",
    "    pattern = r'(\\d+%)'\n",
    "    df['% off'] = df['% off'].str.extract(pattern)\n",
    "    return (df)\n",
    "    \n",
    "def remove_popup():\n",
    "    # Check if an element on the new page is present\n",
    "    try:\n",
    "        close_button  = driver.find_element(By.XPATH, '//button[@class=\"_2KpZ6l _2doB4z\"]')\n",
    "        close_button.click() \n",
    "        print(\"Pop-up removed\")\n",
    "    except NoSuchElementException:\n",
    "        print(\"No pop-up windows was found\")\n",
    "\n",
    "def retrieve_products(n):\n",
    "    ''' Retrieve the products advancing page by page until completing all \"n\" products.\n",
    "        Return: a dataframe with the products'''\n",
    "    # Checking the found records\n",
    "    first, second, total = retrive_product_per_page(driver, '//span[@class=\"_10Ermr\"]')\n",
    "    total_records_to_retrive = n\n",
    "\n",
    "    if(total < total_records_to_retrive):\n",
    "        total_records_to_retrive = total\n",
    "\n",
    "    df_products = pd.DataFrame()\n",
    "    i = 0 \n",
    "\n",
    "    while( total_records_to_retrive > 0 ):\n",
    "\n",
    "        print('*'*40, 'i=' ,i)\n",
    "\n",
    "        wait_time = 10\n",
    "        time.sleep(wait_time)\n",
    "\n",
    "        df = load_products_by_page(driver, total_records_to_retrive) \n",
    "        df_products = pd.concat([df_products,df])\n",
    "\n",
    "        total_records_to_retrive -= len(df)\n",
    "\n",
    "        print(\"total_records_to_retrive left\", total_records_to_retrive)\n",
    "        print(\"retrived records:\", len(df_products))\n",
    "\n",
    "        if (total_records_to_retrive > 0):\n",
    "            wait_random(driver)\n",
    "            go_next_page2(driver, i)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    print( f'Products retrived successfully: {len(df_products)}' )\n",
    "    \n",
    "    # Reseting index\n",
    "    df_products.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return (df_products)\n",
    "        \n",
    "        \n",
    "def search_product(product):\n",
    "    try:\n",
    "        input = driver.find_element(By.XPATH, '//input[@class=\"Pke_EE\" or @class=\"_3704LK\"]') \n",
    "        input.send_keys(product)\n",
    "        print(f\"Search for {product}\")\n",
    "\n",
    "        WebDriverWait(driver, 10)\n",
    "\n",
    "        btn = driver.find_element(By.XPATH, '//button[@class=\"_2iLD__\" or @class=\"L0Z3Pu\"]') \n",
    "        btn.click()\n",
    "        print(\"Click successful\")\n",
    "\n",
    "    except NoSuchElementException:\n",
    "        print(\"An element wasn't found.\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2627271d",
   "metadata": {},
   "source": [
    "Web scraping - Begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "416bf06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "7d1785bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pop-up removed\n"
     ]
    }
   ],
   "source": [
    "driver.get(\"https://www.flipkart.com/\")\n",
    "\n",
    "# Closing pop-up window\n",
    "wait = WebDriverWait(driver, 30)\n",
    "\n",
    "remove_popup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "46dd3bb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search for sunglasses\n",
      "Click successful\n"
     ]
    }
   ],
   "source": [
    "product = 'sunglasses'\n",
    "search_product(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "0afa90e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************** i= 0\n",
      "Brands retrived: 40\n",
      "Desc. retrived: 40\n",
      "Prices retrived: 40\n",
      "% off retived: 40\n",
      "total_records_to_retrive left 60\n",
      "retrived records: 40\n",
      "Waiting..45 seconds.\n",
      "11 NEXT\n",
      "**************************************** i= 1\n",
      "Brands retrived: 40\n",
      "Desc. retrived: 40\n",
      "Prices retrived: 40\n",
      "% off retived: 40\n",
      "total_records_to_retrive left 20\n",
      "retrived records: 80\n",
      "Waiting..60 seconds.\n",
      "12 NEXT\n",
      "**************************************** i= 2\n",
      "Brands retrived: 40\n",
      "Desc. retrived: 40\n",
      "Prices retrived: 40\n",
      "% off retived: 40\n",
      "total_records_to_retrive left 0\n",
      "retrived records: 100\n",
      "Products retrived successfully: 100\n"
     ]
    }
   ],
   "source": [
    "df_products = retrieve_products(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "3c7ead00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the size of dataframe\n",
    "df_products.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "d15d2889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product description</th>\n",
       "      <th>Price</th>\n",
       "      <th>% off</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>SUNBEE</td>\n",
       "      <td>UV Protection Cat-eye Sunglasses (Free Size)</td>\n",
       "      <td>₹195</td>\n",
       "      <td>80%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Eyewearlabs</td>\n",
       "      <td>UV Protection, Polarized Retro Square Sunglass...</td>\n",
       "      <td>₹2,199</td>\n",
       "      <td>38%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>LOUIS KOUROS</td>\n",
       "      <td>UV Protection, Riding Glasses, Mirrored Aviato...</td>\n",
       "      <td>₹1,499</td>\n",
       "      <td>44%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SUNBEE</td>\n",
       "      <td>UV Protection, Polarized, Mirrored Aviator Sun...</td>\n",
       "      <td>₹215</td>\n",
       "      <td>78%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>LIZA ANGEL</td>\n",
       "      <td>UV Protection, Night Vision, Riding Glasses Wa...</td>\n",
       "      <td>₹249</td>\n",
       "      <td>80%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand                                Product description   Price  \\\n",
       "95        SUNBEE       UV Protection Cat-eye Sunglasses (Free Size)    ₹195   \n",
       "96   Eyewearlabs  UV Protection, Polarized Retro Square Sunglass...  ₹2,199   \n",
       "97  LOUIS KOUROS  UV Protection, Riding Glasses, Mirrored Aviato...  ₹1,499   \n",
       "98        SUNBEE  UV Protection, Polarized, Mirrored Aviator Sun...    ₹215   \n",
       "99    LIZA ANGEL  UV Protection, Night Vision, Riding Glasses Wa...    ₹249   \n",
       "\n",
       "   % off  \n",
       "95   80%  \n",
       "96   38%  \n",
       "97   44%  \n",
       "98   78%  \n",
       "99   80%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_products = cleaning_products(df_products)    \n",
    "display(df_products.tail())\n",
    "\n",
    "# Saving the result dataset\n",
    "df_products.to_csv('webScraping2_datasets/q4_products.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "92b8da9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f12003",
   "metadata": {},
   "source": [
    "**Q5:** Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: \n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART\n",
    "\n",
    "As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100reviews.\n",
    "**Note: All the steps required during scraping should be done through code only and not manually.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741a7b65",
   "metadata": {},
   "source": [
    "#### Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "7e1ea1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_items_by_page(driver, n=None, **kwargs):\n",
    "    ''' Load items on the page with the attributes sent in kwargs.\n",
    "        n: number of products required\n",
    "        kwargs: dictionary with key, value = label, XPATH to retrieve \n",
    "        Return: a DataFrame with the info of the products\n",
    "    '''\n",
    "    data_retrieved = {}\n",
    "    lenght_ref = -1\n",
    "    \n",
    "    for key, xpath in kwargs.items():\n",
    "        # scraping Brands using list comprehension\n",
    "        tags = driver.find_elements(By.XPATH, xpath )\n",
    "        items = [ tag.text for tag in tags]\n",
    "        \n",
    "        if(lenght_ref <0):\n",
    "            lenght_ref = len(items)\n",
    "        \n",
    "        if(lenght_ref == len(items)):\n",
    "            data_retrieved[key] = items\n",
    "            print(f\"{key} retrieved and included:\", len(items))\n",
    "        else:\n",
    "            data_retrieved[key] = [None for _ in range(lenght_ref)]\n",
    "            print(f\"{key} retrieved NOT COMPATIBLE:\", len(items))\n",
    "\n",
    "    df = pd.DataFrame(data_retrieved)\n",
    "        \n",
    "    if (n < len(df)):\n",
    "        return (df.iloc[0:n,:])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b70fa07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_reviews(n, dict):\n",
    "    ''' Retrieve the reviews advancing page by page until completing all \"n\" products.\n",
    "        dict : Dictionary with the attributes and xpaths\n",
    "        \n",
    "        Return: a dataframe'''\n",
    "    # Checking the number of records\n",
    "    first, total = retrive_product_per_page(driver, '//div[@class=\"_2MImiq _1Qnn1K\"]/span')\n",
    "    total_records_to_retrive = n\n",
    "    \n",
    "    # Setting the records to retrieve\n",
    "    if(total < total_records_to_retrive):\n",
    "        total_records_to_retrive = total\n",
    "        \n",
    "    df_all = pd.DataFrame()\n",
    "    i = 0 \n",
    "\n",
    "    while( total_records_to_retrive > 0 ):\n",
    "\n",
    "        print('*'*40, 'i=' ,i)\n",
    "        \n",
    "        # Waiting for the page to load\n",
    "        wait_time = 10\n",
    "        time.sleep(wait_time)\n",
    "\n",
    "        df = load_items_by_page(driver, total_records_to_retrive, **dict) \n",
    "        df_all = pd.concat([df_all,df])\n",
    "\n",
    "        total_records_to_retrive -= len(df)\n",
    "\n",
    "        print(\"total_records_to_retrive left\", total_records_to_retrive)\n",
    "        print(\"retrived records:\", len(df_all))\n",
    "\n",
    "        if (total_records_to_retrive > 0):\n",
    "            wait_random(driver)\n",
    "            go_next_page2(driver, i)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    print( f'Records retrived successfully: {len(df_all)}' )\n",
    "    \n",
    "    # Reseting index\n",
    "    df_all.reset_index(drop=True, inplace=True)\n",
    "    return (df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbc0d22",
   "metadata": {},
   "source": [
    "#### Web scraping - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "2477ab86",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "6e9795d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "71d73ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1130\n"
     ]
    }
   ],
   "source": [
    "first, total = retrive_product_per_page(driver, '//div[@class=\"_2MImiq _1Qnn1K\"]/span')\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "9ba4b804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************** i= 0\n",
      "Rating retrieved and included: 10\n",
      "Review sumary retrieved and included: 10\n",
      "Full review retrieved and included: 10\n",
      "total_records_to_retrive left 90\n",
      "retrived records: 10\n",
      "Waiting..60 seconds.\n",
      "11 NEXT\n",
      "**************************************** i= 1\n",
      "Rating retrieved and included: 10\n",
      "Review sumary retrieved and included: 10\n",
      "Full review retrieved and included: 10\n",
      "total_records_to_retrive left 80\n",
      "retrived records: 20\n",
      "Waiting..60 seconds.\n",
      "12 NEXT\n",
      "**************************************** i= 2\n",
      "Rating retrieved and included: 10\n",
      "Review sumary retrieved and included: 10\n",
      "Full review retrieved and included: 10\n",
      "total_records_to_retrive left 70\n",
      "retrived records: 30\n",
      "Waiting..30 seconds.\n",
      "12 NEXT\n",
      "**************************************** i= 3\n",
      "Rating retrieved and included: 10\n",
      "Review sumary retrieved and included: 10\n",
      "Full review retrieved and included: 10\n",
      "total_records_to_retrive left 60\n",
      "retrived records: 40\n",
      "Waiting..15 seconds.\n",
      "12 NEXT\n",
      "**************************************** i= 4\n",
      "Rating retrieved and included: 10\n",
      "Review sumary retrieved and included: 10\n",
      "Full review retrieved and included: 10\n",
      "total_records_to_retrive left 50\n",
      "retrived records: 50\n",
      "Waiting..60 seconds.\n",
      "12 NEXT\n",
      "**************************************** i= 5\n",
      "Rating retrieved and included: 10\n",
      "Review sumary retrieved and included: 10\n",
      "Full review retrieved and included: 10\n",
      "total_records_to_retrive left 40\n",
      "retrived records: 60\n",
      "Waiting..60 seconds.\n",
      "12 NEXT\n",
      "**************************************** i= 6\n",
      "Rating retrieved and included: 10\n",
      "Review sumary retrieved and included: 10\n",
      "Full review retrieved and included: 10\n",
      "total_records_to_retrive left 30\n",
      "retrived records: 70\n",
      "Waiting..30 seconds.\n",
      "12 NEXT\n",
      "**************************************** i= 7\n",
      "Rating retrieved and included: 10\n",
      "Review sumary retrieved and included: 10\n",
      "Full review retrieved and included: 10\n",
      "total_records_to_retrive left 20\n",
      "retrived records: 80\n",
      "Waiting..60 seconds.\n",
      "12 NEXT\n",
      "**************************************** i= 8\n",
      "Rating retrieved and included: 10\n",
      "Review sumary retrieved and included: 10\n",
      "Full review retrieved and included: 10\n",
      "total_records_to_retrive left 10\n",
      "retrived records: 90\n",
      "Waiting..60 seconds.\n",
      "12 NEXT\n",
      "**************************************** i= 9\n",
      "Rating retrieved and included: 10\n",
      "Review sumary retrieved and included: 10\n",
      "Full review retrieved and included: 10\n",
      "total_records_to_retrive left 0\n",
      "retrived records: 100\n",
      "Records retrived successfully: 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review sumary</th>\n",
       "      <th>Full review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Very very good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Camera is awesome\\nBest battery backup\\nA perf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>Value for money 😍</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>This is amazing at all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>Excellent Phone.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>Quality camera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>Best Apple iPhone that i have bought at a very...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>Exactly mach what you expect and where Spent y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>Excellent product but packing was not upto mark..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>Excellent camera 📸 And Display touching very N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating          Review sumary  \\\n",
       "0       5               Terrific   \n",
       "1       5         Classy product   \n",
       "2       5      Terrific purchase   \n",
       "3       5              Wonderful   \n",
       "4       5              Brilliant   \n",
       "..    ...                    ...   \n",
       "5       5              Wonderful   \n",
       "6       5              Must buy!   \n",
       "7       5                 Super!   \n",
       "8       5     Highly recommended   \n",
       "9       5  Mind-blowing purchase   \n",
       "\n",
       "                                          Full review  \n",
       "0                                      Very very good  \n",
       "1   Camera is awesome\\nBest battery backup\\nA perf...  \n",
       "2                                   Value for money 😍  \n",
       "3                              This is amazing at all  \n",
       "4                                    Excellent Phone.  \n",
       "..                                                ...  \n",
       "5                                      Quality camera  \n",
       "6   Best Apple iPhone that i have bought at a very...  \n",
       "7   Exactly mach what you expect and where Spent y...  \n",
       "8   Excellent product but packing was not upto mark..  \n",
       "9   Excellent camera 📸 And Display touching very N...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {\n",
    "    'Rating': '//div[@class=\"_3LWZlK _1BLPMq\"]',\n",
    "    'Review sumary': '//p[@class=\"_2-N8zT\"]',\n",
    "    'Full review': '//div[@class=\"t-ZTKy\"]/div/div'}\n",
    "\n",
    "df_reviews = retrieve_reviews(100, dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ffc19ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "57580193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review sumary</th>\n",
       "      <th>Full review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Very very good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Camera is awesome\\nBest battery backup\\nA perf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>Value for money 😍</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>This is amazing at all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>Excellent Phone.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>Quality camera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>Best Apple iPhone that i have bought at a very...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>Exactly mach what you expect and where Spent y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>Excellent product but packing was not upto mark..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>Excellent camera 📸 And Display touching very N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating          Review sumary  \\\n",
       "0       5               Terrific   \n",
       "1       5         Classy product   \n",
       "2       5      Terrific purchase   \n",
       "3       5              Wonderful   \n",
       "4       5              Brilliant   \n",
       "..    ...                    ...   \n",
       "95      5              Wonderful   \n",
       "96      5              Must buy!   \n",
       "97      5                 Super!   \n",
       "98      5     Highly recommended   \n",
       "99      5  Mind-blowing purchase   \n",
       "\n",
       "                                          Full review  \n",
       "0                                      Very very good  \n",
       "1   Camera is awesome\\nBest battery backup\\nA perf...  \n",
       "2                                   Value for money 😍  \n",
       "3                              This is amazing at all  \n",
       "4                                    Excellent Phone.  \n",
       "..                                                ...  \n",
       "95                                     Quality camera  \n",
       "96  Best Apple iPhone that i have bought at a very...  \n",
       "97  Exactly mach what you expect and where Spent y...  \n",
       "98  Excellent product but packing was not upto mark..  \n",
       "99  Excellent camera 📸 And Display touching very N...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correcting index\n",
    "df_reviews.reset_index(drop=True, inplace=True)\n",
    "df_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e4ca6c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the result dataset\n",
    "df_reviews.to_csv('webScraping2_datasets/q5_reviews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525b4258",
   "metadata": {},
   "source": [
    "**Q6:** Scrape data forfirst 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the \n",
    "search field.\n",
    "\n",
    "You have to scrape 3 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. ProductDescription\n",
    "3. Price\n",
    "\n",
    "As shown in the below image, you have to scrape the above attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30db34e",
   "metadata": {},
   "source": [
    "#### web scraping start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b7b9084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6cafb53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pop-up removed\n"
     ]
    }
   ],
   "source": [
    "driver.get(\"https://www.flipkart.com/\")\n",
    "\n",
    "# Closing pop-up window\n",
    "wait = WebDriverWait(driver, 30)\n",
    "\n",
    "remove_popup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5d16bd24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search for sneakers\n",
      "Click successful\n"
     ]
    }
   ],
   "source": [
    "product = 'sneakers'\n",
    "search_product(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e465d832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************** i= 0\n",
      "Brands retrived: 40\n",
      "Desc. retrived: 40\n",
      "Prices retrived: 40\n",
      "% off retived: 40\n",
      "total_records_to_retrive left 60\n",
      "retrived records: 40\n",
      "Waiting..60 seconds.\n",
      "**************************************** i= 1\n",
      "Brands retrived: 40\n",
      "Desc. retrived: 40\n",
      "Prices retrived: 40\n",
      "% off retived: 40\n",
      "total_records_to_retrive left 20\n",
      "retrived records: 80\n",
      "Waiting..30 seconds.\n",
      "**************************************** i= 2\n",
      "Brands retrived: 40\n",
      "Desc. retrived: 40\n",
      "Prices retrived: 40\n",
      "% off retived: 40\n",
      "total_records_to_retrive left 0\n",
      "retrived records: 100\n",
      "Products retrived successfully: 100\n"
     ]
    }
   ],
   "source": [
    "df_products = retrieve_products(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5ef8f9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_products.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "23f9a1e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product description</th>\n",
       "      <th>Price</th>\n",
       "      <th>% off</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Lightweight,Comfort,Summer,Trendy,Walking,Outd...</td>\n",
       "      <td>₹299</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ASTEROID</td>\n",
       "      <td>Men's Outdoor Color Change Sneakers Colorblock...</td>\n",
       "      <td>₹749</td>\n",
       "      <td>83%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Footox</td>\n",
       "      <td>Men's Shoes | Casual Shoes | Sports Shoes Snea...</td>\n",
       "      <td>₹299</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>asian</td>\n",
       "      <td>Men's W-05 Casual White Sneaker Shoes With Wat...</td>\n",
       "      <td>₹659</td>\n",
       "      <td>34%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Kraasa</td>\n",
       "      <td>Sneakers For Women</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Brand                                Product description Price % off\n",
       "95      aadi  Lightweight,Comfort,Summer,Trendy,Walking,Outd...  ₹299   70%\n",
       "96  ASTEROID  Men's Outdoor Color Change Sneakers Colorblock...  ₹749   83%\n",
       "97    Footox  Men's Shoes | Casual Shoes | Sports Shoes Snea...  ₹299   70%\n",
       "98     asian  Men's W-05 Casual White Sneaker Shoes With Wat...  ₹659   34%\n",
       "99    Kraasa                                 Sneakers For Women  ₹399   60%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cleaning the products and set index\n",
    "cleaning_products(df_products)    \n",
    "display(df_products.tail())\n",
    "\n",
    "# Saving the result dataset\n",
    "df_products.to_csv('webScraping2_datasets/q6_sneakers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7fd97663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5dc7ed",
   "metadata": {},
   "source": [
    "**Q7:** Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then \n",
    "set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87035be",
   "metadata": {},
   "source": [
    "#### web scraping start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "8cc8b9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "dabdd2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.amazon.in/\"\n",
    "driver.get(url) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "9fe193a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "product = 'Laptop'\n",
    "\n",
    "input = driver.find_element(By.XPATH, '//input[@id=\"twotabsearchtextbox\"]') \n",
    "input.send_keys(product)\n",
    "\n",
    "wait = WebDriverWait(driver, 10)\n",
    "\n",
    "btn = driver.find_element(By.XPATH, '//input[@id=\"nav-search-submit-button\"]') \n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "637b57e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the option \"Intel Core i7\"\n",
    "checkbox = driver.find_element(By.XPATH, '//li[@aria-label=\"Intel Core i7\"]/span/a')\n",
    "\n",
    "if checkbox.is_enabled():\n",
    "    checkbox.click()   \n",
    "else:\n",
    "    print(\"Checkbox is disable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "5316cc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = {\n",
    "    'Title': '//span[@class=\"a-size-medium a-color-base a-text-normal\"]',\n",
    "    'Rating': \"a-icon-alt\", #By.CLASS_NAME\n",
    "    'Price': '//span[@class=\"a-price\"]//span[@class=\"a-offscreen\"]',\n",
    "    'container': '//div[@class=\"a-section a-spacing-small a-spacing-top-small\"]'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "c6cc05cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "# Retriving the titles\n",
    "title_tags = driver.find_elements(By.XPATH, attributes['Title'])\n",
    "titles = [el.text for el in title_tags]\n",
    "print(len(titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "da283584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "# Retriving the prices\n",
    "price_tags = driver.find_elements(By.XPATH, attributes['Price'])\n",
    "prices = [el.get_attribute(\"innerHTML\") for el in price_tags][0:len(titles)]\n",
    "print(len(prices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "98f69f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "# Some laptops have rating and others have not, hence each container with the data of the product was retrieved\n",
    "container_tags = driver.find_elements(By.XPATH, attributes['container'])\n",
    "\n",
    "ratings = []\n",
    "\n",
    "for tag in container_tags[1:]:\n",
    "    try:\n",
    "        item = tag.find_element(By.CLASS_NAME, attributes['Rating'])\n",
    "        ratings.append(item.get_attribute(\"innerHTML\"))\n",
    "    except NoSuchElementException:\n",
    "        ratings.append(None)\n",
    "    \n",
    "print(len(ratings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "6bd61253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASUS Vivobook 15, Intel Core i7-12650H 12th Ge...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>₹64,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo [SmartChoice] IdeaPad Slim 3 Intel Core...</td>\n",
       "      <td>2.5 out of 5 stars</td>\n",
       "      <td>₹62,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acer Nitro 5 AN515-58 Gaming Laptop 12th Gen I...</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>₹1,04,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MSI GF63 Thin, Intel Core i7-11800H, 40CM FHD ...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>₹71,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP Pavilion 14, 11Th Gen Intel Core I7-16Gb Ra...</td>\n",
       "      <td>3.6 out of 5 stars</td>\n",
       "      <td>₹79,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lenovo Ideapad Gaming 3 Intel Core i7 10th Gen...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>₹64,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>₹89,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ASUS TUF Gaming F15 (2023) 90WHr Battery, Inte...</td>\n",
       "      <td>4.5 out of 5 stars</td>\n",
       "      <td>₹1,15,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "      <td>₹80,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dell Vostro 5630 13th Gen Laptop, Intel Core i...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>₹90,004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title              Rating  \\\n",
       "0  ASUS Vivobook 15, Intel Core i7-12650H 12th Ge...  4.1 out of 5 stars   \n",
       "1  Lenovo [SmartChoice] IdeaPad Slim 3 Intel Core...  2.5 out of 5 stars   \n",
       "2  Acer Nitro 5 AN515-58 Gaming Laptop 12th Gen I...  4.3 out of 5 stars   \n",
       "3  MSI GF63 Thin, Intel Core i7-11800H, 40CM FHD ...  4.0 out of 5 stars   \n",
       "4  HP Pavilion 14, 11Th Gen Intel Core I7-16Gb Ra...  3.6 out of 5 stars   \n",
       "5  Lenovo Ideapad Gaming 3 Intel Core i7 10th Gen...  4.1 out of 5 stars   \n",
       "6  HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...  4.0 out of 5 stars   \n",
       "7  ASUS TUF Gaming F15 (2023) 90WHr Battery, Inte...  4.5 out of 5 stars   \n",
       "8  Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...  4.4 out of 5 stars   \n",
       "9  Dell Vostro 5630 13th Gen Laptop, Intel Core i...  5.0 out of 5 stars   \n",
       "\n",
       "       Price  \n",
       "0    ₹64,990  \n",
       "1    ₹62,990  \n",
       "2  ₹1,04,990  \n",
       "3    ₹71,990  \n",
       "4    ₹79,990  \n",
       "5    ₹64,999  \n",
       "6    ₹89,990  \n",
       "7  ₹1,15,990  \n",
       "8    ₹80,990  \n",
       "9    ₹90,004  "
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_laptops = 10\n",
    "\n",
    "laptops_df = pd.DataFrame({'Title': titles[:total_laptops],\n",
    "                           'Rating': ratings[:total_laptops],\n",
    "                           'Price': prices[:total_laptops]\n",
    "                          })\n",
    "\n",
    "laptops_df.to_csv('webScraping2_datasets/q7_laptops.csv')\n",
    "laptops_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "183e584f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d3bf66",
   "metadata": {},
   "source": [
    "**Q8:** Write a python program to scrape data for Top 1000 Quotes of All Time.\n",
    "The above task will be done in following steps:\n",
    "1. First get the webpage https://www.azquotes.com/\n",
    "2. Click on TopQuotes\n",
    "3. Than scrap a) Quote b) Author c) Type Of Quotes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e0101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_reviews(n, dict):\n",
    "    ''' Retrieve the reviews advancing page by page until completing all \"n\" products.\n",
    "        dict : Dictionary with the attributes and xpaths\n",
    "        \n",
    "        Return: a dataframe'''\n",
    "    # Checking the number of records\n",
    "    first, total = retrive_product_per_page(driver, '//div[@class=\"_2MImiq _1Qnn1K\"]/span')\n",
    "    total_records_to_retrive = n\n",
    "    \n",
    "    # Setting the records to retrieve\n",
    "    if(total < total_records_to_retrive):\n",
    "        total_records_to_retrive = total\n",
    "        \n",
    "    df_all = pd.DataFrame()\n",
    "    i = 0 \n",
    "\n",
    "    while( total_records_to_retrive > 0 ):\n",
    "\n",
    "        print('*'*40, 'i=' ,i)\n",
    "        \n",
    "        # Waiting for the page to load\n",
    "        wait_time = 10\n",
    "        time.sleep(wait_time)\n",
    "\n",
    "        df = load_items_by_page(driver, total_records_to_retrive, **dict) \n",
    "        df_all = pd.concat([df_all,df])\n",
    "\n",
    "        total_records_to_retrive -= len(df)\n",
    "\n",
    "        print(\"total_records_to_retrive left\", total_records_to_retrive)\n",
    "        print(\"retrived records:\", len(df_all))\n",
    "\n",
    "        if (total_records_to_retrive > 0):\n",
    "            wait_random(driver)\n",
    "            go_next_page2(driver, i)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    print( f'Records retrived successfully: {len(df_all)}' )\n",
    "    \n",
    "    # Reseting index\n",
    "    df_all.reset_index(drop=True, inplace=True)\n",
    "    return (df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "0f53bfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_next_page(driver, xpath):\n",
    "    ''' Go to the next page'''\n",
    "        \n",
    "    next_btn = driver.find_element(By.XPATH, xpath)\n",
    "    \n",
    "    # scroll until button be visible\n",
    "    actions = ActionChains(driver)\n",
    "    actions.move_to_element(next_btn).perform()\n",
    "\n",
    "    # Wait until the button be visible (loading compleated)\n",
    "    wait = WebDriverWait(driver, 15)\n",
    "    wait.until(EC.element_to_be_clickable((By.XPATH, xpath)))\n",
    "\n",
    "    # Click the button once it is clickable\n",
    "    next_btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03592fed",
   "metadata": {},
   "source": [
    "#### web scraping start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "28451a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "\n",
    "wait_time = 3\n",
    "time.sleep(wait_time)\n",
    "\n",
    "url = \"https://www.azquotes.com/\"\n",
    "driver.get(url) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "b996a4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Quotes clicked\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    link_tq = driver.find_element(By.XPATH, '//a[starts-with(@href,\"/top_quotes\")]')\n",
    "    link_tq.click()\n",
    "    print(\"Top Quotes clicked\")\n",
    "except NoSuchElementException:\n",
    "    print(\"Top Quotes link wasn't find\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "2b6207af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_el(webelement):\n",
    "    return webelement.text\n",
    "\n",
    "def get_topics_el(webelement):\n",
    "    return ([link.text for link in webelement.find_elements(By.TAG_NAME, 'a')])\n",
    "\n",
    "def load_quotes_by_page(driver, n=None, **kwargs):\n",
    "    ''' Load items on the page with the attributes sended in kwargs.\n",
    "        n: number of products required\n",
    "        kwargs: dictionary with key, value = label, XPATH to retrieve \n",
    "        Return: a DataFrame with the info of the products\n",
    "    '''\n",
    "    block_tags = driver.find_elements(By.XPATH, '//div[@class=\"wrap-block\"]')\n",
    "\n",
    "    data_retrieved = {}\n",
    "\n",
    "    for key, value in attribute.items():\n",
    "        print(key,value[0])\n",
    "        items = [b.find_element(By.CLASS_NAME, value[0]) for b in block_tags]\n",
    "\n",
    "        items = [value[1](i) for i in items]\n",
    "        data_retrieved[key] = items\n",
    "        print(len(items))\n",
    "\n",
    "    df = pd.DataFrame(data_retrieved)\n",
    "\n",
    "    if (n < len(df)):\n",
    "        return (df.iloc[0:n,:])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "0d2f0e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quote title\n",
      "100\n",
      "Author author\n",
      "100\n",
      "Type Of Quotes tags\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "attribute = {'Quote': ['title', lambda wel: text_el(wel)],\n",
    "            'Author': ['author', lambda wel: text_el(wel)],\n",
    "            'Type Of Quotes': ['tags', lambda wel: get_topics_el(wel)]}\n",
    "\n",
    "total_quotes = 1000\n",
    "total_records_to_retrive = 1000\n",
    "\n",
    "df = load_quotes_by_page(driver, total_records_to_retrive, **attribute )\n",
    "# df_all = pd.concat([df_all,df])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "51f33b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Essence', 'Deep Thought', 'Transcendentalism']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote</th>\n",
       "      <th>Author</th>\n",
       "      <th>Type Of Quotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "      <td>Michael Porter</td>\n",
       "      <td>[Essence, Deep Thought, Transcendentalism]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "      <td>Golda Meir</td>\n",
       "      <td>[Inspiration, Past, Trying]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>[Country, Peace, War]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "      <td>Nelson Mandela</td>\n",
       "      <td>[Inspirational, Motivational, Death]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "      <td>Erma Bombeck</td>\n",
       "      <td>[4th Of July, Food, Patriotic]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>When the going gets weird, the weird turn pro.</td>\n",
       "      <td>Hunter S. Thompson</td>\n",
       "      <td>[Music, Sports, Hunting]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>When a train goes through a tunnel and it gets...</td>\n",
       "      <td>Corrie Ten Boom</td>\n",
       "      <td>[Trust, Encouraging, Uplifting]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>If you think you are too small to make a diffe...</td>\n",
       "      <td>Dalai Lama</td>\n",
       "      <td>[Inspirational, Funny, Change]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>God doesn't require us to succeed, he only req...</td>\n",
       "      <td>Mother Teresa</td>\n",
       "      <td>[Success, God, Mother]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Change your thoughts and you change your world.</td>\n",
       "      <td>Norman Vincent Peale</td>\n",
       "      <td>[Inspirational, Motivational, Change]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Quote                Author  \\\n",
       "0   The essence of strategy is choosing what not t...        Michael Porter   \n",
       "1   One cannot and must not try to erase the past ...            Golda Meir   \n",
       "2   Patriotism means to stand by the country. It d...    Theodore Roosevelt   \n",
       "3   Death is something inevitable. When a man has ...        Nelson Mandela   \n",
       "4   You have to love a nation that celebrates its ...          Erma Bombeck   \n",
       "..                                                ...                   ...   \n",
       "95     When the going gets weird, the weird turn pro.    Hunter S. Thompson   \n",
       "96  When a train goes through a tunnel and it gets...       Corrie Ten Boom   \n",
       "97  If you think you are too small to make a diffe...            Dalai Lama   \n",
       "98  God doesn't require us to succeed, he only req...         Mother Teresa   \n",
       "99    Change your thoughts and you change your world.  Norman Vincent Peale   \n",
       "\n",
       "                                Type Of Quotes  \n",
       "0   [Essence, Deep Thought, Transcendentalism]  \n",
       "1                  [Inspiration, Past, Trying]  \n",
       "2                        [Country, Peace, War]  \n",
       "3         [Inspirational, Motivational, Death]  \n",
       "4               [4th Of July, Food, Patriotic]  \n",
       "..                                         ...  \n",
       "95                    [Music, Sports, Hunting]  \n",
       "96             [Trust, Encouraging, Uplifting]  \n",
       "97              [Inspirational, Funny, Change]  \n",
       "98                      [Success, God, Mother]  \n",
       "99       [Inspirational, Motivational, Change]  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0,:]['Quote']\n",
    "df.iloc[0,:]['Author']\n",
    "print(df.iloc[0,:]['Type Of Quotes'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "374df97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "go_next_page(driver, '//li[@class=\"next\"]//a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "08c54625",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93860add",
   "metadata": {},
   "source": [
    "**Q9:** Write a python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead, \n",
    "Term of office, Remarks) from https://www.jagranjosh.com/.\n",
    "\n",
    "This task will be done in following steps:\n",
    "1. First get the webpagehttps://www.jagranjosh.com/\n",
    "2. Then You have to click on the GK option\n",
    "3. Then click on the List of all Prime Ministers of India\n",
    "4. Then scrap the mentioned data and make theDataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2b2844",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7770946d",
   "metadata": {},
   "source": [
    "**Q10:** Write a python program to display list of 50 Most expensive cars in the world (i.e. \n",
    "Car name and Price) from https://www.motor1.com/\n",
    "\n",
    "This task will be done in following steps:\n",
    "1. First get the webpagehttps://www.motor1.com/\n",
    "2. Then You have to type in the search bar ’50 most expensive cars’\n",
    "3. Then click on 50 most expensive carsin the world..\n",
    "4. Then scrap the mentioned data and make the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c347ffef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
